use burn::backend::wgpu::WgpuDevice;
use burn::backend::{Autodiff, Wgpu};
use burn::optim::decay::WeightDecayConfig;
use burn::optim::{AdamConfig, GradientsParams, Optimizer};
use burn::prelude::*;
use burn::tensor::activation;

use rand::RngExt;

use burn_raymarching::camera::create_camera_rays;
use burn_raymarching::model::scene::SceneModel;
use burn_raymarching::util::{load_image_as_tensor, save_tensor_as_image};

fn main() {
    type MyBackend = Autodiff<Wgpu>;
    let device = WgpuDevice::default();

    // --------------------------------------------------------
    // è¨­å®š: çƒã‚’100å€‹ã«å¢—ã‚„ã™
    // --------------------------------------------------------
    const BATCH_SIZE: usize = 8192; // VRAMã«åˆã‚ã›ã¦èª¿æ•´ (2048~8192ãã‚‰ã„)

    let width = 256;
    let height = 256;

    // --- 1. ã‚«ãƒ¡ãƒ©ã¨æ­£è§£ç”»åƒã®æº–å‚™ ---
    // å„è¦–ç‚¹ã®ãƒ¬ã‚¤ç”Ÿæˆ (æˆ»ã‚Šå€¤ã¯ [H*W, 3])
    let (ro1, rd1) = create_camera_rays::<MyBackend>(
        width,
        height,
        [0.0, 0.0, -2.5],
        [0.0, 0.0, 0.0],
        50.0,
        &device,
    );
    let (ro2, rd2) = create_camera_rays::<MyBackend>(
        width,
        height,
        [2.5, 0.0, 0.0],
        [0.0, 0.0, 0.0],
        50.0,
        &device,
    );
    let (ro3, rd3) = create_camera_rays::<MyBackend>(
        width,
        height,
        [0.0, 2.5, -0.0001],
        [0.0, 0.0, 0.0],
        50.0,
        &device,
    );

    // æ­£è§£ç”»åƒã®ãƒ­ãƒ¼ãƒ‰ (3æ¬¡å…ƒ [H, W, 3] ã§æ¥ã‚‹ã®ã§ ãƒ•ãƒ©ãƒƒãƒˆ [H*W, 3] ã«ã™ã‚‹)
    let t1 = load_image_as_tensor::<MyBackend>("data/target_1.png", &device)
        .reshape([-1, 3])
        .detach();
    let t2 = load_image_as_tensor::<MyBackend>("data/target_2.png", &device)
        .reshape([-1, 3])
        .detach();
    let t3 = load_image_as_tensor::<MyBackend>("data/target_3.png", &device)
        .reshape([-1, 3])
        .detach();

    // --- 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆ ---
    // å…¨ã¦ã®è¦–ç‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦ã€å·¨å¤§ãªã€Œå­¦ç¿’ç”¨ãƒ—ãƒ¼ãƒ«ã€ã‚’ä½œã‚‹
    let train_rays_o = Tensor::cat(vec![ro1.clone(), ro2.clone(), ro3.clone()], 0).detach(); // [TotalPixels, 3]
    let train_rays_d = Tensor::cat(vec![rd1.clone(), rd2.clone(), rd3.clone()], 0).detach();
    let train_targets = Tensor::cat(vec![t1, t2, t3], 0).detach();

    let num_total_pixels = train_rays_o.dims()[0];
    println!("Total training pixels: {}", num_total_pixels);

    // --- 2.5 ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åŠ¹ç‡åŒ–ã®ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹äº‹å‰è¨ˆç®— (CPUå´) ---
    let targets_data: Vec<f32> = train_targets
        .clone()
        .into_data()
        .convert::<f32>()
        .to_vec()
        .unwrap();
    let mut fg_indices = Vec::new();
    let mut bg_indices = Vec::new();

    for i in 0..num_total_pixels {
        let idx = i * 3;
        let sum_color = targets_data[idx] + targets_data[idx + 1] + targets_data[idx + 2];

        // è‰²ã®åˆè¨ˆãŒä¸€å®šä»¥ä¸Šãªã‚‰ç‰©ä½“ï¼ˆå‰æ™¯ï¼‰ã€ãã†ã§ãªã‘ã‚Œã°èƒŒæ™¯
        if sum_color > 0.05 {
            fg_indices.push(i as i32);
        } else {
            bg_indices.push(i as i32);
        }
    }
    println!(
        "Foreground pixels: {}, Background pixels: {}",
        fg_indices.len(),
        bg_indices.len()
    );

    // ==========================================
    // 1. åˆæœŸè¨­å®š (æœ€åˆã¯5å€‹ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆ)
    // ==========================================
    let mut current_n = 5;
    let mut centers_vec = vec![0.0; current_n * 3];
    let mut colors_vec = vec![0.0; current_n * 3]; // Logit 0.0 (ã‚°ãƒ¬ãƒ¼)
    let mut radii_vec = vec![0.0; current_n]; // Softplus(-2.0) â‰’ 0.12

    // åˆæœŸä½ç½®ã‚’å°‘ã—ã ã‘æ•£ã‚‰ã™
    for i in 0..current_n {
        centers_vec[i * 3 + 0] = (i as f32 * 0.1) - 0.2;
    }

    const STAGES: usize = 5; // ä¸–ä»£æ•° (ä¾‹: 5ä¸–ä»£)
    const STEPS_PER_STAGE: usize = 600; // 1ä¸–ä»£ã‚ãŸã‚Šã®å­¦ç¿’å›æ•°
    const TOTAL_STEPS: f32 = (STAGES * STEPS_PER_STAGE) as f32;

    println!("ğŸš€ Start Multi-Stage Optimization...");

    // ==========================================
    // 2. ä¸–ä»£ï¼ˆStageï¼‰ãƒ«ãƒ¼ãƒ—
    // ==========================================
    for stage in 0..STAGES {
        println!("=== Stage {}/{} (N = {}) ===", stage + 1, STAGES, current_n);

        // --- A. ãƒ¢ãƒ‡ãƒ«ã¨Optimizerã®å†æ§‹ç¯‰ ---
        let init_centers = Tensor::<MyBackend, 1>::from_floats(centers_vec.as_slice(), &device)
            .reshape([current_n, 3]);
        let init_colors = Tensor::<MyBackend, 1>::from_floats(colors_vec.as_slice(), &device)
            .reshape([current_n, 3]);
        let init_radii = Tensor::<MyBackend, 1>::from_floats(radii_vec.as_slice(), &device)
            .reshape([current_n, 1]);

        let mut model = SceneModel::new(init_centers, init_colors, init_radii);

        // â˜…é‡è¦: ã‚¹ãƒ†ãƒ¼ã‚¸ã”ã¨ã«Adamã‚’ä½œã‚Šç›´ã™ï¼ˆå¤ã„ãƒ†ãƒ³ã‚½ãƒ«ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦çˆ†ç™ºã‚’é˜²ãï¼‰
        let mut optim = AdamConfig::new()
            .with_weight_decay(Some(WeightDecayConfig::new(1e-5)))
            .init();

        // å­¦ç¿’ç‡ã‚‚ã‚¹ãƒ†ãƒ¼ã‚¸ãŒé€²ã‚€ã«ã¤ã‚Œã¦å°‘ã—ãšã¤ä¸‹ã’ã‚‹
        let base_lr = 0.05 * (0.6f64).powi(stage as i32);

        // --- B. 1ä¸–ä»£åˆ†ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ— ---
        for step in 1..=STEPS_PER_STAGE {
            let global_step = (stage * STEPS_PER_STAGE + step) as f32;
            let progress = global_step / TOTAL_STEPS;

            // [ã“ã“ã§å…ˆã»ã©ã®ã€Œã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ã®ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ã€ã¨ã€Œkã®ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ã€ã‚’è¡Œã†]
            let smooth_k = 5.0 + (32.0 - 5.0) * progress;
            // --- ãƒãƒƒãƒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ---
            let mut rng = rand::rng();

            // --- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ã®ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚° ---
            let uniform_ratio = 0.8 - (0.6 * progress); // 0.8 -> 0.2 ã«æ¸›å°‘

            let mut uniform_batch_size = (BATCH_SIZE as f32 * uniform_ratio) as usize;
            let mut fg_boost_batch_size = BATCH_SIZE - uniform_batch_size;

            // å‰æ™¯ãƒ”ã‚¯ã‚»ãƒ«æ•°ãŒå°‘ãªã„å ´åˆã®ã‚­ãƒ£ãƒƒãƒ—å‡¦ç†
            if !fg_indices.is_empty() && fg_indices.len() < fg_boost_batch_size {
                fg_boost_batch_size = fg_indices.len();
                uniform_batch_size = BATCH_SIZE - fg_boost_batch_size;
            }

            let mut batch_indices = Vec::with_capacity(BATCH_SIZE);

            // 1. å…¨ä½“ã‹ã‚‰ã®æŠ½å‡º
            for _ in 0..uniform_batch_size {
                batch_indices.push(rng.random_range(0..num_total_pixels as i32));
            }

            // 2. å‰æ™¯ã‹ã‚‰ã®æŠ½å‡º
            if !fg_indices.is_empty() && fg_boost_batch_size > 0 {
                for _ in 0..fg_boost_batch_size {
                    let idx = rng.random_range(0..fg_indices.len());
                    batch_indices.push(fg_indices[idx]);
                }
            }

            // Intå‹ã®Tensorã¨ã—ã¦ç”Ÿæˆ
            let indices = Tensor::<MyBackend, 1, Int>::from_ints(batch_indices.as_slice(), &device);

            // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º (Gather)
            let batch_ro = train_rays_o.clone().select(0, indices.clone()).detach();
            let batch_rd = train_rays_d.clone().select(0, indices.clone()).detach();
            let batch_target = train_targets.clone().select(0, indices).detach();

            let output = model.forward(batch_ro, batch_rd, smooth_k);

            // ==========================================
            // --- Lossè¨ˆç®— ---
            // ==========================================

            // 1. ç”»åƒå†æ§‹æˆLoss (ãƒ¡ã‚¤ãƒ³ã®å­¦ç¿’ç›®æ¨™)
            // ------------------------------------------
            let diff = output - batch_target.clone();
            let mse_map = diff.clone().powf_scalar(2.0);
            let abs_diff = diff.abs();

            let target_sum = batch_target.sum_dim(1);
            let target_mask = target_sum.greater_elem(0.01); // ç‰©ä½“é ˜åŸŸã®åˆ¤å®š

            // ç‰©ä½“é ˜åŸŸã¯å³ã—ã(L1 * 10)ã€èƒŒæ™¯ã¯ç·©ã(MSE)
            let reconstruction_loss = mse_map.mask_where(target_mask, abs_diff * 10.0).mean();
            let mut loss = reconstruction_loss;

            // 2. å¹¾ä½•å­¦çš„åˆ¶ç´„ (ãƒšãƒŠãƒ«ãƒ†ã‚£é …)
            // ------------------------------------------
            let centers = model.centers.val();
            let radii = activation::softplus(model.radius.val(), 1.0);

            // [a] åŠå¾„ãƒšãƒŠãƒ«ãƒ†ã‚£: çƒãŒå¤§ãããªã‚Šã™ãã‚‹ã®ã‚’é˜²ãã¤ã¤ã€ä¸è¦ãªçƒã‚’å°ã•ãã™ã‚‹
            let radius_l1_penalty = radii.clone().abs().mean();

            let r_mask = radii.clone().greater_elem(1.0);
            let radius_large_penalty = Tensor::zeros_like(&radii)
                .mask_where(r_mask, radii.clone().powf_scalar(2.0))
                .mean();

            loss = loss + radius_large_penalty * 0.1 + radius_l1_penalty * 0.004;

            // [b] åŸç‚¹å¼•åŠ›: çƒãŒãƒãƒ©ãƒãƒ©ã«æ•£ã‚‰ã°ã‚‹ã®ã‚’é˜²ã
            let center_penalty = centers.clone().powf_scalar(2.0).mean();
            loss = loss + center_penalty * 0.1; // Billboardå¯¾ç­–ã§å°‘ã—å¼·ã‚ã«è¨­å®š

            // [c] ã‚«ãƒ¡ãƒ©è¿‘æ¥ãƒãƒªã‚¢ (Billboard Effectå¯¾ç­–ã®è¦)
            let centers_val = model.centers.val();

            // ä¸­å¿ƒã®åŸç‚¹ã‹ã‚‰ã®è·é›¢: [N, 3] -> [N, 1]
            let dist_from_origin = (centers_val.powf_scalar(2.0).sum_dim(1) + 1e-6).sqrt();

            // çƒã®è¡¨é¢ãŒä¸€ç•ªå¤–å´ã«å¼µã‚Šå‡ºã™è·é›¢ (ä¸­å¿ƒè·é›¢ + åŠå¾„)
            let max_reach = dist_from_origin + radii;

            // å¢ƒç•Œç·š 1.2 ã‚’è¶…ãˆã¦ã„ã‚‹ã‹ã©ã†ã‹ã®ãƒã‚¹ã‚¯
            let out_of_bounds_mask = max_reach.clone().greater_elem(1.2);
            let excess_dist = max_reach.clone() - 1.1;
            let penalty_values = excess_dist.powf_scalar(2.0);

            let camera_proximity_penalty = Tensor::zeros_like(&max_reach)
                .mask_where(out_of_bounds_mask, penalty_values)
                .mean();

            loss = loss + camera_proximity_penalty * 5.0;

            // [d] åç™ºé …: çƒåŒå£«ã®é‡ãªã‚Šã‚’é˜²ã
            let centers_val = model.centers.val();
            let c_sq_val = centers_val.clone().powf_scalar(2.0).sum_dim(1); // [N, 1]
            let c_sq_t = c_sq_val.clone().transpose(); // [1, N]
            let c_dot_c = centers_val.clone().matmul(centers_val.clone().transpose()); // [N, N]

            let dist_sq = c_sq_val + c_sq_t - c_dot_c * 2.0; // [N, N]
            let dist_matrix = dist_sq.clamp_min(1e-6).sqrt(); // [N, N]
            let eye = Tensor::<MyBackend, 2>::eye(current_n, &device);
            let repulsion_loss = (dist_matrix + eye * 100.0 + 1e-6).powf_scalar(-1.0).mean();
            loss = loss + repulsion_loss * 0.00001;

            let grads = loss.backward();
            let grads = GradientsParams::from_grads(grads, &model);

            // ã‚¹ãƒ†ãƒ¼ã‚¸å†…ã§ã‚‚å¾ŒåŠã¯å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹
            let current_lr = if step > STEPS_PER_STAGE / 2 {
                base_lr * 0.2
            } else {
                base_lr
            };
            model = optim.step(current_lr, model, grads);

            if step % 100 == 0 {
                println!(
                    "  Step {} | Loss: {:.5} | k: {:.1}",
                    step,
                    loss.into_scalar(),
                    smooth_k
                );
            }
        }

        if stage == STAGES - 1 {
            println!("ğŸ‰ Final Stage Complete! Exporting results...");

            // 1. ç‰©ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç¢ºå®šå€¤ï¼‰ã®å–ã‚Šå‡ºã—
            let centers_tensor = model.centers.val();
            let colors_tensor = activation::sigmoid(model.colors.val()); // è‰²ã‚’0~1ã«
            let radii_tensor = activation::softplus(model.radius.val(), 1.0); // åŠå¾„ã‚’æ­£ã®å€¤ã«

            let final_centers: Vec<f32> = centers_tensor
                .into_data()
                .convert::<f32>()
                .to_vec()
                .unwrap();
            let final_colors: Vec<f32> =
                colors_tensor.into_data().convert::<f32>().to_vec().unwrap();
            let final_radii: Vec<f32> = radii_tensor.into_data().convert::<f32>().to_vec().unwrap();

            // 2. JSONã¸ã®ä¿å­˜
            #[derive(serde::Serialize)]
            struct SceneData {
                num_spheres: usize,
                centers: Vec<f32>,
                colors: Vec<f32>,
                radii: Vec<f32>,
            }

            let data = SceneData {
                num_spheres: current_n,
                centers: final_centers,
                colors: final_colors,
                radii: final_radii,
            };

            let file = std::fs::File::create("scene.json").expect("Failed to create file");
            serde_json::to_writer_pretty(file, &data).expect("Failed to write json");
            println!("  => Saved to scene.json (N = {})", current_n);

            // 3. æœ€çµ‚ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ç”»åƒã®ä¿å­˜
            println!("  => Rendering final images...");
            // ï¼ˆro1, rd1 ãªã©ãŒã“ã®ã‚¹ã‚³ãƒ¼ãƒ—ã§å–ã‚Œã‚‹ãªã‚‰ãã®ã¾ã¾æ¸¡ã™ï¼‰
            save_tiled_preview(
                &model,
                ro1.clone(),
                rd1.clone(),
                width,
                height,
                "steps/final_1.png",
            );
            save_tiled_preview(
                &model,
                ro2.clone(),
                rd2.clone(),
                width,
                height,
                "steps/final_2.png",
            );
            save_tiled_preview(
                &model,
                ro3.clone(),
                rd3.clone(),
                width,
                height,
                "steps/final_3.png",
            );

            // å…¨ã¦å®Œäº†ã—ãŸã®ã§ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
            break;
        }

        save_tiled_preview(
            &model,
            ro1.clone(),
            rd1.clone(),
            width,
            height,
            &format!("steps/stage_{stage}.png"),
        );

        // --- C. ä¸–ä»£äº¤ä»£ãƒ•ã‚§ãƒ¼ã‚º: Pruning (å‰Šé™¤) & Splitting (åˆ†è£‚) ---
        let out_centers: Vec<f32> = model
            .centers
            .val()
            .into_data()
            .convert::<f32>()
            .to_vec()
            .unwrap();
        let out_colors: Vec<f32> = model
            .colors
            .val()
            .into_data()
            .convert::<f32>()
            .to_vec()
            .unwrap();
        let eval_radii: Vec<f32> = activation::softplus(model.radius.val(), 1.0)
            .into_data()
            .convert::<f32>()
            .to_vec()
            .unwrap();

        let mut next_centers = Vec::new();
        let mut next_colors = Vec::new();
        let mut next_radii = Vec::new();

        let mut mut_rng = rand::rng();

        for i in 0..current_n {
            let r = eval_radii[i];
            let cx = out_centers[i * 3];
            let cy = out_centers[i * 3 + 1];
            let cz = out_centers[i * 3 + 2];
            let cr = out_colors[i * 3];
            let cg = out_colors[i * 3 + 1];
            let cb = out_colors[i * 3 + 2];

            // 1. Pruning (å‰Šé™¤): ãƒ‡ã‚«ã™ãã‚‹å½±(0.25è¶…ãˆ)ã‚„ã€æ¥µå°ã®ã‚´ãƒŸ(0.01æœªæº€)ã¯æ¬¡ä¸–ä»£ã«å¼•ãç¶™ãŒãªã„
            if r > 0.25 || r < 0.01 {
                continue;
            }

            // 2. Keep (ç¶­æŒ): ç”Ÿå­˜ã—ãŸçƒã¯ãã®ã¾ã¾æ¬¡ä¸–ä»£ã¸
            next_centers.extend_from_slice(&[cx, cy, cz]);
            next_colors.extend_from_slice(&[cr, cg, cb]);
            next_radii.push(-2.5); // åŠå¾„ã¯å°‘ã—å°ã•ã‚ã«å†åˆæœŸåŒ–

            // 3. Splitting (åˆ†è£‚): æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¸ä»¥å¤–ãªã‚‰ã€ç”Ÿãæ®‹ã£ãŸçƒã‚’åˆ†è£‚ã•ã›ã¦è¡¨ç¾åŠ›ã‚’ä¸Šã’ã‚‹
            if stage < STAGES - 1 {
                // åˆ†è£‚å…ˆã¯ã€å…ƒã®ä½ç½®ã‹ã‚‰ã‚ãšã‹ã«ãƒã‚¤ã‚ºã‚’ä¹—ã›ã¦ã‚ºãƒ©ã™
                let offset_x = (mut_rng.random_range(0.0..1.0) - 0.5) * 0.05;
                let offset_y = (mut_rng.random_range(0.0..1.0) - 0.5) * 0.05;
                let offset_z = (mut_rng.random_range(0.0..1.0) - 0.5) * 0.05;

                next_centers.extend_from_slice(&[cx + offset_x, cy + offset_y, cz + offset_z]);
                next_colors.extend_from_slice(&[cr, cg, cb]); // è‰²ã¯å¼•ãç¶™ã
                next_radii.push(-2.5);
            }
        }

        // æ¬¡ä¸–ä»£ã®æƒ…å ±ã‚’ã‚»ãƒƒãƒˆ
        current_n = next_radii.len();
        centers_vec = next_centers;
        colors_vec = next_colors;
        radii_vec = next_radii;
        println!("  => Pruning & Splitting complete. Next N = {}", current_n);
    }
}

// --- ãƒ˜ãƒ«ãƒ‘ãƒ¼: ã‚¿ã‚¤ãƒ«åˆ†å‰²ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° (VRAMç¯€ç´„) ---
// Autodiffãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã¾ã¾æ¨è«–ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒä½œã‚‰ã‚Œã¦é‡ã„ã®ã§ã€
// å¿…è¦ãªã‚‰ .detach() ã—ãŸã‚Šã€å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†ã‘ã¦å‡¦ç†ã™ã‚‹
fn save_tiled_preview<B: Backend>(
    model: &SceneModel<B>,
    rays_o: Tensor<B, 2>, // [H*W, 3]
    rays_d: Tensor<B, 2>,
    width: usize,
    height: usize,
    path: &str,
) {
    let num_pixels = width * height;
    let chunk_size = 4096; // æ¨è«–æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
    let mut outputs = Vec::new();

    let mut start = 0;
    while start < num_pixels {
        let end = (start + chunk_size).min(num_pixels);
        let batch_ro = rays_o.clone().slice([start..end]);
        let batch_rd = rays_d.clone().slice([start..end]);

        // æ¨è«– (å‹¾é…ä¸è¦ãªã®ã§ detach ã—ã¦ã‚‚ã„ã„ãŒã€Model::forward ãŒ tensor ã‚’è¿”ã™ã®ã§
        // è¿”ã‚Šå€¤ã‚’ detach ã™ã‚‹ã®ãŒç°¡å˜)
        let out = model.forward(batch_ro, batch_rd, 32.0).detach();
        outputs.push(out);
        start += chunk_size;
    }

    // çµåˆã—ã¦ç”»åƒã«æˆ»ã™
    let full_img_flat = Tensor::cat(outputs, 0);

    save_tensor_as_image(full_img_flat, width as u32, height as u32, path);
}
