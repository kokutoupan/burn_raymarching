use burn::backend::wgpu::WgpuDevice;
use burn::backend::{Autodiff, Wgpu};
use burn::optim::decay::WeightDecayConfig;
use burn::optim::{AdamConfig, GradientsParams, Optimizer};
use burn::prelude::*;
use burn::tensor::activation;

use burn_raymarching::camera::create_camera_rays;
use burn_raymarching::dataset::SceneDataset;
use burn_raymarching::model::scene::SceneModel;
use burn_raymarching::training::{compute_loss, prune_and_split};
use burn_raymarching::util::{load_image_as_tensor, save_tensor_as_image};

fn main() {
    type MyBackend = Autodiff<Wgpu>;
    let device = WgpuDevice::default();

    // --------------------------------------------------------
    // è¨­å®š: çƒã‚’100å€‹ã«å¢—ã‚„ã™
    // --------------------------------------------------------
    const BATCH_SIZE: usize = 8192; // VRAMã«åˆã‚ã›ã¦èª¿æ•´ (2048~8192ãã‚‰ã„)

    let width = 256;
    let height = 256;

    // --- 1. ã‚«ãƒ¡ãƒ©ã¨æ­£è§£ç”»åƒã®æº–å‚™ ---
    // å„è¦–ç‚¹ã®ãƒ¬ã‚¤ç”Ÿæˆ (æˆ»ã‚Šå€¤ã¯ [H*W, 3])
    let (ro1, rd1) = create_camera_rays::<MyBackend>(
        width,
        height,
        [0.0, 0.0, -2.5],
        [0.0, 0.0, 0.0],
        50.0,
        &device,
    );
    let (ro2, rd2) = create_camera_rays::<MyBackend>(
        width,
        height,
        [2.5, 0.0, 0.0],
        [0.0, 0.0, 0.0],
        50.0,
        &device,
    );
    let (ro3, rd3) = create_camera_rays::<MyBackend>(
        width,
        height,
        [0.0, 2.5, -0.0001],
        [0.0, 0.0, 0.0],
        50.0,
        &device,
    );

    // æ­£è§£ç”»åƒã®ãƒ­ãƒ¼ãƒ‰ (3æ¬¡å…ƒ [H, W, 3] ã§æ¥ã‚‹ã®ã§ ãƒ•ãƒ©ãƒƒãƒˆ [H*W, 3] ã«ã™ã‚‹)
    let t1 = load_image_as_tensor::<MyBackend>("data/target_1.png", &device)
        .reshape([-1, 3])
        .detach();
    let t2 = load_image_as_tensor::<MyBackend>("data/target_2.png", &device)
        .reshape([-1, 3])
        .detach();
    let t3 = load_image_as_tensor::<MyBackend>("data/target_3.png", &device)
        .reshape([-1, 3])
        .detach();

    // --- 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆ ---
    // å…¨ã¦ã®è¦–ç‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦ã€å·¨å¤§ãªã€Œå­¦ç¿’ç”¨ãƒ—ãƒ¼ãƒ«ã€ã‚’ä½œã‚‹
    let train_rays_o = Tensor::cat(vec![ro1.clone(), ro2.clone(), ro3.clone()], 0).detach(); // [TotalPixels, 3]
    let train_rays_d = Tensor::cat(vec![rd1.clone(), rd2.clone(), rd3.clone()], 0).detach();
    let train_targets = Tensor::cat(vec![t1, t2, t3], 0).detach();

    let dataset = SceneDataset::new(train_rays_o, train_rays_d, train_targets);
    println!("Total training pixels: {}", dataset.num_total_pixels);
    println!(
        "Foreground pixels: {}, Background pixels: {}",
        dataset.fg_indices.len(),
        dataset.bg_indices.len()
    );

    // ==========================================
    // 1. åˆæœŸè¨­å®š (æœ€åˆã¯5å€‹ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆ)
    // ==========================================
    let mut current_n = 5;
    let mut centers_vec = vec![0.0; current_n * 3];
    let mut colors_vec = vec![0.0; current_n * 3]; // Logit 0.0 (ã‚°ãƒ¬ãƒ¼)
    let mut radii_vec = vec![0.0; current_n]; // Softplus(-2.0) â‰’ 0.12

    // åˆæœŸä½ç½®ã‚’å°‘ã—ã ã‘æ•£ã‚‰ã™
    for i in 0..current_n {
        centers_vec[i * 3 + 0] = (i as f32 * 0.1) - 0.2;
    }

    const STAGES: usize = 5; // ä¸–ä»£æ•° (ä¾‹: 5ä¸–ä»£)
    const STEPS_PER_STAGE: usize = 600; // 1ä¸–ä»£ã‚ãŸã‚Šã®å­¦ç¿’å›æ•°
    const TOTAL_STEPS: f32 = (STAGES * STEPS_PER_STAGE) as f32;

    println!("ğŸš€ Start Multi-Stage Optimization...");

    // ==========================================
    // 2. ä¸–ä»£ï¼ˆStageï¼‰ãƒ«ãƒ¼ãƒ—
    // ==========================================
    for stage in 0..STAGES {
        println!("=== Stage {}/{} (N = {}) ===", stage + 1, STAGES, current_n);

        // --- A. ãƒ¢ãƒ‡ãƒ«ã¨Optimizerã®å†æ§‹ç¯‰ ---
        let init_centers = Tensor::<MyBackend, 1>::from_floats(centers_vec.as_slice(), &device)
            .reshape([current_n, 3]);
        let init_colors = Tensor::<MyBackend, 1>::from_floats(colors_vec.as_slice(), &device)
            .reshape([current_n, 3]);
        let init_radii = Tensor::<MyBackend, 1>::from_floats(radii_vec.as_slice(), &device)
            .reshape([current_n, 1]);

        let mut model = SceneModel::new(init_centers, init_colors, init_radii);

        // â˜…é‡è¦: ã‚¹ãƒ†ãƒ¼ã‚¸ã”ã¨ã«Adamã‚’ä½œã‚Šç›´ã™ï¼ˆå¤ã„ãƒ†ãƒ³ã‚½ãƒ«ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦çˆ†ç™ºã‚’é˜²ãï¼‰
        let mut optim = AdamConfig::new()
            .with_weight_decay(Some(WeightDecayConfig::new(1e-5)))
            .init();

        // å­¦ç¿’ç‡ã‚‚ã‚¹ãƒ†ãƒ¼ã‚¸ãŒé€²ã‚€ã«ã¤ã‚Œã¦å°‘ã—ãšã¤ä¸‹ã’ã‚‹
        let base_lr = 0.05 * (0.6f64).powi(stage as i32);

        // --- B. 1ä¸–ä»£åˆ†ã®å­¦ç¿’ãƒ«ãƒ¼ãƒ— ---
        for step in 1..=STEPS_PER_STAGE {
            let global_step = (stage * STEPS_PER_STAGE + step) as f32;
            let progress = global_step / TOTAL_STEPS;

            // [ã“ã“ã§å…ˆã»ã©ã®ã€Œã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ã®ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ã€ã¨ã€Œkã®ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ã€ã‚’è¡Œã†]
            let smooth_k = 5.0 + (32.0 - 5.0) * progress;
            // --- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ã®ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚° ---
            let uniform_ratio = 0.8 - (0.6 * progress); // 0.8 -> 0.2 ã«æ¸›å°‘

            // --- ãƒãƒƒãƒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ---
            let (batch_ro, batch_rd, batch_target) =
                dataset.sample_batch(BATCH_SIZE, uniform_ratio, &device);

            let output = model.forward(batch_ro, batch_rd, smooth_k);

            // ==========================================
            // --- Lossè¨ˆç®— ---
            // ==========================================
            let loss = compute_loss(&model, output, batch_target);

            let grads = loss.backward();
            let grads = GradientsParams::from_grads(grads, &model);

            // ã‚¹ãƒ†ãƒ¼ã‚¸å†…ã§ã‚‚å¾ŒåŠã¯å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹
            let current_lr = if step > STEPS_PER_STAGE / 2 {
                base_lr * 0.2
            } else {
                base_lr
            };
            model = optim.step(current_lr, model, grads);

            if step % 100 == 0 {
                println!(
                    "  Step {} | Loss: {:.5} | k: {:.1}",
                    step,
                    loss.into_scalar(),
                    smooth_k
                );
            }
        }

        if stage == STAGES - 1 {
            println!("ğŸ‰ Final Stage Complete! Exporting results...");

            // 1. ç‰©ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç¢ºå®šå€¤ï¼‰ã®å–ã‚Šå‡ºã—
            let centers_tensor = model.centers.val();
            let colors_tensor = activation::sigmoid(model.colors.val()); // è‰²ã‚’0~1ã«
            let radii_tensor = activation::softplus(model.radius.val(), 1.0); // åŠå¾„ã‚’æ­£ã®å€¤ã«

            let final_centers: Vec<f32> = centers_tensor
                .into_data()
                .convert::<f32>()
                .to_vec()
                .unwrap();
            let final_colors: Vec<f32> =
                colors_tensor.into_data().convert::<f32>().to_vec().unwrap();
            let final_radii: Vec<f32> = radii_tensor.into_data().convert::<f32>().to_vec().unwrap();

            // 2. JSONã¸ã®ä¿å­˜
            #[derive(serde::Serialize)]
            struct SceneData {
                num_spheres: usize,
                centers: Vec<f32>,
                colors: Vec<f32>,
                radii: Vec<f32>,
            }

            let data = SceneData {
                num_spheres: current_n,
                centers: final_centers,
                colors: final_colors,
                radii: final_radii,
            };

            let file = std::fs::File::create("scene.json").expect("Failed to create file");
            serde_json::to_writer_pretty(file, &data).expect("Failed to write json");
            println!("  => Saved to scene.json (N = {})", current_n);

            // 3. æœ€çµ‚ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ç”»åƒã®ä¿å­˜
            println!("  => Rendering final images...");
            // ï¼ˆro1, rd1 ãªã©ãŒã“ã®ã‚¹ã‚³ãƒ¼ãƒ—ã§å–ã‚Œã‚‹ãªã‚‰ãã®ã¾ã¾æ¸¡ã™ï¼‰
            save_tiled_preview(
                &model,
                ro1.clone(),
                rd1.clone(),
                width,
                height,
                "steps/final_1.png",
            );
            save_tiled_preview(
                &model,
                ro2.clone(),
                rd2.clone(),
                width,
                height,
                "steps/final_2.png",
            );
            save_tiled_preview(
                &model,
                ro3.clone(),
                rd3.clone(),
                width,
                height,
                "steps/final_3.png",
            );

            // å…¨ã¦å®Œäº†ã—ãŸã®ã§ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
            break;
        }

        save_tiled_preview(
            &model,
            ro1.clone(),
            rd1.clone(),
            width,
            height,
            &format!("steps/stage_{stage}.png"),
        );

        // --- C. ä¸–ä»£äº¤ä»£ãƒ•ã‚§ãƒ¼ã‚º: Pruning (å‰Šé™¤) & Splitting (åˆ†è£‚) ---
        let (next_centers, next_colors, next_radii, next_n) =
            prune_and_split(&model, centers_vec.as_slice(), stage, STAGES);

        // æ¬¡ä¸–ä»£ã®æƒ…å ±ã‚’ã‚»ãƒƒãƒˆ
        current_n = next_n;
        centers_vec = next_centers;
        colors_vec = next_colors;
        radii_vec = next_radii;
        println!("  => Pruning & Splitting complete. Next N = {}", current_n);
    }
}

// --- ãƒ˜ãƒ«ãƒ‘ãƒ¼: ã‚¿ã‚¤ãƒ«åˆ†å‰²ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° (VRAMç¯€ç´„) ---
// Autodiffãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã¾ã¾æ¨è«–ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒä½œã‚‰ã‚Œã¦é‡ã„ã®ã§ã€
// å¿…è¦ãªã‚‰ .detach() ã—ãŸã‚Šã€å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†ã‘ã¦å‡¦ç†ã™ã‚‹
fn save_tiled_preview<B: Backend>(
    model: &SceneModel<B>,
    rays_o: Tensor<B, 2>, // [H*W, 3]
    rays_d: Tensor<B, 2>,
    width: usize,
    height: usize,
    path: &str,
) {
    let num_pixels = width * height;
    let chunk_size = 4096; // æ¨è«–æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
    let mut outputs = Vec::new();

    let mut start = 0;
    while start < num_pixels {
        let end = (start + chunk_size).min(num_pixels);
        let batch_ro = rays_o.clone().slice([start..end]);
        let batch_rd = rays_d.clone().slice([start..end]);

        // æ¨è«– (å‹¾é…ä¸è¦ãªã®ã§ detach ã—ã¦ã‚‚ã„ã„ãŒã€Model::forward ãŒ tensor ã‚’è¿”ã™ã®ã§
        // è¿”ã‚Šå€¤ã‚’ detach ã™ã‚‹ã®ãŒç°¡å˜)
        let out = model.forward(batch_ro, batch_rd, 32.0).detach();
        outputs.push(out);
        start += chunk_size;
    }

    // çµåˆã—ã¦ç”»åƒã«æˆ»ã™
    let full_img_flat = Tensor::cat(outputs, 0);

    save_tensor_as_image(full_img_flat, width as u32, height as u32, path);
}
